{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "import torch\n",
    "import evaluate\n",
    "from utils import save_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHI3 SHORT STORY MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1cdd490fceb4e0296be1e4430dd9cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a3a45ec4db4457be6165a8a512caf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00a1d18ee8549b69901b1b8d82c767c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fc590a5ed14e468eba62c1e2a0c025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80cb7e15f9804249a75bfe5653a700cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f8eaa510784e21800a1b0c4e2fffc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/675 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a652c594aa5545e3a9ce3531176c4cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40462c0112324546b8d8fadc8092075f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64f9b1cbda14524b50f3fe2fbe1fe23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ba9aa29a6a4c368c462b2ddd2cdb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.65G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa88275dd2d141e78c81d32155bda438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae16db05c47498aa8bb5b65536be889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/140 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_model = \"unsloth/Phi-3-mini-4k-instruct\"\n",
    "model_id = \"oztrkoguz/phi3_short_story_merged_bfloat16\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "You are a AI writer who creates stories in various genres. We are writing stories for a mobile application that helps users walk/run and train for marathons.  \n",
      "The genre and description will come by user input called Prompt.\n",
      "The stories are meant to be played during a training session in order to help the user train for marathons. \n",
      "The story should have embedded cues for speed changes and breaks where approriate depending on the Training Style.\n",
      "\n",
      "### Input:\n",
      "Can you help me write a story with the following details:\n",
      "Prompt: A zombie horror story set in New York City.\n",
      "Distance: 2 miles\n",
      "Average Walking Speed: 2 mph\n",
      "Average Running Speed: 5 mph\n",
      "Training Style: Short-distance sprint\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "You are a AI writer who creates stories in various genres. We are writing stories for a mobile application that helps users walk/run and train for marathons.  \n",
    "The genre and description will come by user input called Prompt.\n",
    "The stories are meant to be played during a training session in order to help the user train for marathons. \n",
    "The story should have embedded cues for speed changes and breaks where approriate depending on the Training Style.\n",
    "\n",
    "### Input:\n",
    "Can you help me write a story with the following details:\n",
    "Prompt: A zombie horror story set in New York City.\n",
    "Distance: 2 miles\n",
    "Average Walking Speed: 2 mph\n",
    "Average Running Speed: 5 mph\n",
    "Training Style: Short-distance sprint\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "print(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "You are a AI writer who creates stories in various genres. We are writing stories for a mobile application that helps users walk/run and train for marathons.  \n",
      "The genre and description will come by user input called Prompt.\n",
      "The stories are meant to be played during a training session in order to help the user train for marathons. \n",
      "The story should have embedded cues for speed changes and breaks where approriate depending on the Training Style.\n",
      "\n",
      "### Input:\n",
      "Can you help me write a story with the following details:\n",
      "Prompt: A zombie horror story set in New York City.\n",
      "Distance: 2 miles\n",
      "Average Walking Speed: 2 mph\n",
      "Average Running Speed: 5 mph\n",
      "Training Style: Short-distance sprint\n",
      "\n",
      "### Response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pmahi\\OneDrive\\Desktop\\MP\\Drexel\\Courses\\CS614-900 - Applications in Machine Learning\\Projects\\Natural_Language_Assignment\\.venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pmahi\\OneDrive\\Desktop\\MP\\Drexel\\Courses\\CS614-900 - Applications in Machine Learning\\Projects\\Natural_Language_Assignment\\.venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:674: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's nighttime at Times Square as people run away from horrifying creatures known only under one name - ZOMBIES! The scene shifts between running through crowded streets of NYC while dodging dead bodies left behind after being attacked or killed; then suddenly stopping when they see something ahead (a car) which turns out not really dangerous but just another obstacle along their path towards safety... Then we cut back into our main character walking down Broadway before he starts joggling his way up West Street until finally reaching Central Park near Columbus Circle without any problems whatsoever except maybe some minor injuries caused due too much stress over these past few minutes.. He continues forward now faster than ever because there aren´t many places around here anymore so if someone wants escape this hellhole better hurry!!<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hyperparams = {\n",
    "    \"max_new_tokens\": 512, \n",
    "    \"temperature\":0.6, \n",
    "    \"repetition_penalty\":2.0, \n",
    "    \"no_repeat_ngram_size\":1\n",
    "}\n",
    "encoded_input = tokenizer([input_text], return_tensors='pt').to(\"cuda\")\n",
    "streamer = TextStreamer(tokenizer)\n",
    "response = model.generate(input_ids=encoded_input.input_ids, \n",
    "                        streamer=streamer, \n",
    "                        max_new_tokens=hyperparams[\"max_new_tokens\"], \n",
    "                        temperature=hyperparams[\"temperature\"], \n",
    "                        repetition_penalty=hyperparams[\"repetition_penalty\"], \n",
    "                        no_repeat_ngram_size=hyperparams[\"no_repeat_ngram_size\"]).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "You are a AI writer who creates stories in various genres. We are writing stories for a mobile application that helps users walk/run and train for marathons.  \n",
      "The genre and description will come by user input called Prompt.\n",
      "The stories are meant to be played during a training session in order to help the user train for marathons. \n",
      "The story should have embedded cues for speed changes and breaks where approriate depending on the Training Style.\n",
      "\n",
      "### Input:\n",
      "Can you help me write a story with the following details:\n",
      "Prompt: A zombie horror story set in New York City.\n",
      "Distance: 2 miles\n",
      "Average Walking Speed: 2 mph\n",
      "Average Running Speed: 5 mph\n",
      "Training Style: Short-distance sprint\n",
      "\n",
      "### Response:\n",
      "It's nighttime at Times Square as people run away from horrifying creatures known only under one name - ZOMBIES! The scene shifts between running through crowded streets of NYC while dodging dead bodies left behind after being attacked or killed; then suddenly stopping when they see something ahead (a car) which turns out not really dangerous but just another obstacle along their path towards safety... Then we cut back into our main character walking down Broadway before he starts joggling his way up West Street until finally reaching Central Park near Columbus Circle without any problems whatsoever except maybe some minor injuries caused due too much stress over these past few minutes.. He continues forward now faster than ever because there aren´t many places around here anymore so if someone wants escape this hellhole better hurry!!\n"
     ]
    }
   ],
   "source": [
    "output = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_response(\"PHI3-SHORT-STORY\", hyperparams, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "# input_texts = [\"lorem ipsum\", \"Happy Birthday!\", \"Bienvenue\"]\n",
    "# results = perplexity.compute(model_id=model_id,\n",
    "#                              add_start_token=False,\n",
    "#                              predictions=input_texts, \n",
    "#                              device=\"cuda\")\n",
    "# print(list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(round(results[\"mean_perplexity\"], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
