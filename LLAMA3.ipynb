{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import evaluate\n",
    "from utils import save_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3 - 8B Instruct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe6a208ebb54ac2b32517b34cd44dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\colin\\OneDrive\\Desktop\\Applied ML\\NLP Assignment\\Natural_Language_Assignment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\colin\\.cache\\huggingface\\hub\\models--meta-llama--Meta-Llama-3-8B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763084cbf65b4b239e6229c04e422a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962fe6e89d4747cda48e6ca0305dd7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c483232a38419191588955e87a6d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6a6fa6fc2d411c988ef360716d6e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0be30610734143a1648e9b0a0abd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e16b721d814a78aa28e97520eb0942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67153fc2ace41859a58fe6abc03c36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502c51cb66764d10a906808e8746f62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e11dfb98e7a4d3ab58d69c2b02e7d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919a846e6947458e98fca3a958cfe652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4534d7ad86924bddacfe08d3076da85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"You are a AI writer who creates stories in various genres. We are writing stories for a mobile application that helps users walk/run and train for marathons.  \n",
    "The genre and description will come by user input called Prompt.\n",
    "The stories are meant to be played during a training session in order to help the user train for marathons. \n",
    "The story should have embedded cues for speed changes and breaks where approriate depending on the Training Style.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"Can you help me write a story with the following details:\n",
    "Prompt: A zombie horror story set in New York City.\n",
    "Distance: 2 miles\n",
    "Average Walking Speed: 2 mph\n",
    "Average Running Speed: 5 mph\n",
    "Training Style: Short-distance sprint\"\"\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "c:\\Users\\colin\\OneDrive\\Desktop\\Applied ML\\NLP Assignment\\Natural_Language_Assignment\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:649: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"max_new_tokens\": 512, \n",
    "    \"temperature\":0.6, \n",
    "    \"top_p\":0.9, \n",
    "    \"do_sample\": True\n",
    "}\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=hyperparams[\"max_new_tokens\"],\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=hyperparams[\"do_sample\"],\n",
    "    temperature=hyperparams[\"temperature\"],\n",
    "    top_p=hyperparams[\"top_p\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a zombie horror story set in New York City for a 0.5-mile training session with a short-distance sprint training style.\n",
      "\n",
      "**Story: \"The Brooklyn Bridge Apocalypse\"**\n",
      "\n",
      "You're a survivor of a zombie outbreak in New York City. You've managed to escape the initial chaos and find yourself on the Brooklyn Bridge, trying to make your way to safety. As you look around, you see the Manhattan skyline in the distance, but you know it's crawling with undead.\n",
      "\n",
      "You start your journey, your heart racing with every step. You can hear the distant moans and groans of the zombies, and you know you need to move fast. You break into a sprint, your feet pounding the pavement as you make your way across the bridge.\n",
      "\n",
      "**Cue: Speed up to 5 mph**\n",
      "\n",
      "As you run, you notice the zombies are getting closer. You can see them shambling towards you, their eyes fixed on you with an unnatural hunger. You pick up speed, your breathing heavy as you try to outrun the undead.\n",
      "\n",
      "Suddenly, you hear a loud thud behind you. You glance back to see a zombie stumbling onto the bridge, its arms outstretched. You don't hesitate, pushing yourself to run even faster.\n",
      "\n",
      "**Cue: Sprint for 0.25 miles**\n",
      "\n",
      "You're almost halfway across the bridge when you see a group of survivors huddled together, trying to escape the chaos. You spot a safe haven and make a beeline for it.\n",
      "\n",
      "As you approach, you notice the survivors are armed and ready to defend themselves. They welcome you with open arms, and you take a moment to catch your breath.\n",
      "\n",
      "**Cue: Walk for 0.15 miles**\n",
      "\n",
      "But your respite is short-lived. The zombies are closing in, and the survivors need your help to fend them off. You grab a nearby bat and join the fight, swinging it wildly at the undead.\n",
      "\n",
      "**Cue: Sprint for 0.1 miles**\n",
      "\n",
      "You manage to fend off the zombies, but you know you need to keep moving. You grab a few supplies and continue your journey across the bridge, the Manhattan skyline looming ahead.\n",
      "\n",
      "As you near the end of the bridge, you see a glimmer of hope â€“ a safe zone, marked by a bright light. You sprint towards it, the zombies hot on your heels.\n",
      "\n",
      "**Cue: Sprint to the finish**\n",
      "\n",
      "You burst through the gates, exhausted but alive. You've made it to safety, but you know the fight is far from over.\n"
     ]
    }
   ],
   "source": [
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "output = tokenizer.decode(response, skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msave_response\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLAMA3-8B-INSTRUCT\u001b[39m\u001b[38;5;124m\"\u001b[39m, hyperparams, output)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'save_response' is not defined"
     ]
    }
   ],
   "source": [
    "save_response(\"LLAMA3-8B-INSTRUCT\", hyperparams, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "# input_texts = [\"lorem ipsum\", \"Happy Birthday!\", \"Bienvenue\"]\n",
    "# results = perplexity.compute(model_id=model_id,\n",
    "#                              add_start_token=False,\n",
    "#                              predictions=input_texts, \n",
    "#                              device=\"cuda\")\n",
    "# print(list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(round(results[\"mean_perplexity\"], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
