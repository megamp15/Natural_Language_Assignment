{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marathon Training Application Story Template\n",
    "##### Objective: Create an engaging story template for a marathon training application that adapts to user prompts, running metrics, and training styles. This story template will be used to generate specific stories based on user inputs and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "import torch\n",
    "import evaluate\n",
    "from utils import save_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral-7B Instruct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pmahi\\OneDrive\\Desktop\\MP\\Drexel\\Courses\\CS614-900 - Applications in Machine Learning\\Projects\\Natural_Language_Assignment\\.venv\\Lib\\site-packages\\accelerate\\utils\\modeling.py:1365: UserWarning: Current model requires 318769536 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9dd7a38b034b24a5222f263afe1123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model_id =\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction:\n",
      "We have created a fitness app that helps users train for marathons. The app uses stories to help users train. The stories are generated based on user input/biometric data. \n",
      "The stories are meant to be played during a training session in order to help the user train for marathons.\n",
      "You are a AI writer who's job is to create stories in various genres.\n",
      "The genre and description will come by user input called Prompt.\n",
      "The story should have embedded cues for user speed changes and breaks where approriate depending on the Training Style.\n",
      "\n",
      "### Input:\n",
      "Can you help me write a template story with the following details:\n",
      "Prompt: A superhero adventure story with Spiderman set in New York City.\n",
      "Distance: 0.5 miles\n",
      "Average Walking Speed: 2 mph\n",
      "Average Running Speed: 5 mph\n",
      "Training Style: Short-distance sprint\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Constants for prompt generation\n",
    "INSTRUCTION_KEY = \"### Instruction:\"\n",
    "INPUT_KEY = \"### Input:\"\n",
    "RESPONSE_KEY = \"### Response:\"\n",
    "\n",
    "INSTRUCTION = \"\"\"We have created a fitness app that helps users train for marathons. The app uses stories to help users train. The stories are generated based on user input/biometric data. \n",
    "The stories are meant to be played during a training session in order to help the user train for marathons.\n",
    "You are a AI writer who's job is to create stories in various genres.\n",
    "The genre and description will come by user input called Prompt.\n",
    "The story should have embedded cues for user speed changes and breaks where approriate depending on the Training Style.\n",
    "\"\"\"\n",
    "\n",
    "INPUT = \"\"\"Can you help me write a template story with the following details:\n",
    "Prompt: A superhero adventure story with Spiderman set in New York City.\n",
    "Distance: 0.5 miles\n",
    "Average Walking Speed: 2 mph\n",
    "Average Running Speed: 5 mph\n",
    "Training Style: Short-distance sprint\n",
    "\"\"\"\n",
    "\n",
    "input_text = \"\"\"\n",
    "{instruction_key}\n",
    "{instruction}\n",
    "{input_key}\n",
    "{input}\n",
    "{response_key}\n",
    "\"\"\".format(\n",
    "    instruction_key=INSTRUCTION_KEY,\n",
    "    instruction=INSTRUCTION,\n",
    "    input_key=INPUT_KEY, \n",
    "    input=INPUT,\n",
    "    response_key=RESPONSE_KEY,\n",
    ")\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pmahi\\OneDrive\\Desktop\\MP\\Drexel\\Courses\\CS614-900 - Applications in Machine Learning\\Projects\\Natural_Language_Assignment\\.venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> \n",
      "### Instruction:\n",
      "We have created a fitness app that helps users train for marathons. The app uses stories to help users train. The stories are generated based on user input/biometric data. \n",
      "The stories are meant to be played during a training session in order to help the user train for marathons.\n",
      "You are a AI writer who's job is to create stories in various genres.\n",
      "The genre and description will come by user input called Prompt.\n",
      "The story should have embedded cues for user speed changes and breaks where approriate depending on the Training Style.\n",
      "\n",
      "### Input:\n",
      "Can you help me write a template story with the following details:\n",
      "Prompt: A superhero adventure story with Spiderman set in New York City.\n",
      "Distance: 0.5 miles\n",
      "Average Walking Speed: 2 mph\n",
      "Average Running Speed: 5 mph\n",
      "Training Style: Short-distance sprint\n",
      "\n",
      "### Response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pmahi\\OneDrive\\Desktop\\MP\\Drexel\\Courses\\CS614-900 - Applications in Machine Learning\\Projects\\Natural_Language_Assignment\\.venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:674: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title : \"SpiderMan’ s High Stakes Sprint\" (Length - Approximate words count =  134) [Note, this response has been designed keeping your requirements of average walking & running speeds as well short distance sprinter style] . Here it goes...!🕷️🚀✈✨🔥💪🏼‍♂🌍❤🎉🙌🏻😊👍🏽👏🏾💯👌😉😎😍😂🤣😅😆🙂😁😀😄 :) !!!!!! **Story:** In an exhilarating tale unfolding across bustling NYC streets , our hero – *the agile* ***SPIDERMAN*** *(swings into action)* from his webby lair high above Times Square when he senses danger lurking nearby.* As villainous forces gather at Central Park*, ready**to unleash chaos**, only one man can stop them!* With time tickin', Peter Parker donns His iconic red suit*(start walk mode @ avg_walkspeed=`~{aversageWalkSpeed}`miles per hour*)and swifts through traffic like water flowing downstream*. He reaches CP just before evil doers begin their assault.(end `break`) Now comes THE MOMENT OF TRUTH!(begin runmode@avgRunningspeed={averagerunning}mpheorhours). Swinging onto park benches,*our websliding wallcrawler races against clock(short burst runs interspaced between longer strides), dodging obstacles left right center while battlin'*Green Gobln','Doc Ock,'Venom'(each character appearing briefly but menacingly enough!) until reaching Bethesda Fountains edge.**With each step closer towards victory,(user takes shorter breathless pauses*), SPIDEY gains momentum; finally catching up wit hhis nemesis(*insert climactic battle scene here*). Just then (*as enemy weakens under spidey power punch or some other cool move ), Time expires**. Our Hero saves day once again leaving city cheering wildely below him.. And so ends another thrilling chapter **(End Run Mode)**of life among these friendly neighborhood heroes we all know&love....until next mission comrades!!!! #MarathonPrep#SuperheroesUnite🙏💖💕✌💜♥⚡⭐💎💰🤔🤷♀?👀🙄😏😳😢😭😡😤😬😔☺👉 Up Next:- Your personalized playlist featuring songs inspired b y today\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"max_new_tokens\": 512, \n",
    "    \"temperature\":0.6, \n",
    "    \"repetition_penalty\":2.0, \n",
    "    \"no_repeat_ngram_size\":1\n",
    "}\n",
    "encoded_input = tokenizer(input_text, return_tensors='pt').to(\"cuda\")\n",
    "streamer = TextStreamer(tokenizer)\n",
    "response = model.generate(input_ids=encoded_input.input_ids, \n",
    "                        streamer=streamer, \n",
    "                        max_new_tokens=hyperparams[\"max_new_tokens\"], \n",
    "                        temperature=hyperparams[\"temperature\"], \n",
    "                        repetition_penalty=hyperparams[\"repetition_penalty\"], \n",
    "                        no_repeat_ngram_size=hyperparams[\"no_repeat_ngram_size\"]).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction:\n",
      "We have created a fitness app that helps users train for marathons. The app uses stories to help users train. The stories are generated based on user input/biometric data. \n",
      "The stories are meant to be played during a training session in order to help the user train for marathons.\n",
      "You are a AI writer who's job is to create stories in various genres.\n",
      "The genre and description will come by user input called Prompt.\n",
      "The story should have embedded cues for user speed changes and breaks where approriate depending on the Training Style.\n",
      "\n",
      "### Input:\n",
      "Can you help me write a template story with the following details:\n",
      "Prompt: A superhero adventure story with Spiderman set in New York City.\n",
      "Distance: 0.5 miles\n",
      "Average Walking Speed: 2 mph\n",
      "Average Running Speed: 5 mph\n",
      "Training Style: Short-distance sprint\n",
      "\n",
      "### Response:\n",
      "Title : \"SpiderMan’ s High Stakes Sprint\" (Length - Approximate words count =  134) [Note, this response has been designed keeping your requirements of average walking & running speeds as well short distance sprinter style] . Here it goes...!🕷️🚀✈✨🔥💪🏼‍♂🌍❤🎉🙌🏻😊👍🏽👏🏾💯👌😉😎😍😂🤣😅😆🙂😁😀😄 :) !!!!!! **Story:** In an exhilarating tale unfolding across bustling NYC streets , our hero – *the agile* ***SPIDERMAN*** *(swings into action)* from his webby lair high above Times Square when he senses danger lurking nearby.* As villainous forces gather at Central Park*, ready**to unleash chaos**, only one man can stop them!* With time tickin', Peter Parker donns His iconic red suit*(start walk mode @ avg_walkspeed=`~{aversageWalkSpeed}`miles per hour*)and swifts through traffic like water flowing downstream*. He reaches CP just before evil doers begin their assault.(end `break`) Now comes THE MOMENT OF TRUTH!(begin runmode@avgRunningspeed={averagerunning}mpheorhours). Swinging onto park benches,*our websliding wallcrawler races against clock(short burst runs interspaced between longer strides), dodging obstacles left right center while battlin'*Green Gobln','Doc Ock,'Venom'(each character appearing briefly but menacingly enough!) until reaching Bethesda Fountains edge.**With each step closer towards victory,(user takes shorter breathless pauses*), SPIDEY gains momentum; finally catching up wit hhis nemesis(*insert climactic battle scene here*). Just then (*as enemy weakens under spidey power punch or some other cool move ), Time expires**. Our Hero saves day once again leaving city cheering wildely below him.. And so ends another thrilling chapter **(End Run Mode)**of life among these friendly neighborhood heroes we all know&love....until next mission comrades!!!! #MarathonPrep#SuperheroesUnite🙏💖💕✌💜♥⚡⭐💎💰🤔🤷♀?👀🙄😏😳😢😭😡😤😬😔☺👉 Up Next:- Your personalized playlist featuring songs inspired b y today\n"
     ]
    }
   ],
   "source": [
    "output = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_response(\"MISTRAL-7B-Instructv0.3\", hyperparams, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "# input_texts = [\"lorem ipsum\", \"Happy Birthday!\", \"Bienvenue\"]\n",
    "# results = perplexity.compute(model_id=model_id,\n",
    "#                              add_start_token=False,\n",
    "#                              predictions=input_texts, \n",
    "#                              device=\"cuda\")\n",
    "# print(list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(round(results[\"mean_perplexity\"], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
