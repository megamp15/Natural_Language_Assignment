{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import evaluate\n",
    "from utils import save_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3 - 8B Instruct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fe0ede2d8a4746bd8790e9c25c09d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"You are a AI writer who creates stories in various genres. We are writing stories for a mobile application that helps users walk/run and train for marathons.  \n",
    "The genre and description will come by user input called Prompt.\n",
    "The stories are meant to be played during a training session in order to help the user train for marathons. \n",
    "The story should have embedded cues for speed changes and breaks where approriate depending on the Training Style.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"Can you help me write a story with the following details:\n",
    "Prompt: A action packed adventure story based off of Indiana Jones, include outrunning deadly traps, a chase scene with a treasure hunter and a villain, jungles and ancient ruins.\n",
    "Distance: 13.1 miles\n",
    "Average Walking Speed: 2.5 mph\n",
    "Average Running Speed: 7.2 mph\n",
    "Training Style: Half Marathon\"\"\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "c:\\Users\\colin\\OneDrive\\Desktop\\Applied ML\\NLP Assignment\\Natural_Language_Assignment\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:649: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"max_new_tokens\": 750, \n",
    "    \"temperature\":0.6, \n",
    "    \"top_p\":0.9, \n",
    "    \"do_sample\": True\n",
    "}\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=hyperparams[\"max_new_tokens\"],\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=hyperparams[\"do_sample\"],\n",
    "    temperature=hyperparams[\"temperature\"],\n",
    "    top_p=hyperparams[\"top_p\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a story for you:\n",
      "\n",
      "**The Quest for the Golden Idol**\n",
      "\n",
      "As I ventured deeper into the dense jungle, the air grew thick with humidity and the sounds of exotic birds and animals echoed through the trees. I had been searching for weeks, following cryptic clues and ancient maps, to uncover the location of the legendary Golden Idol. Rumors whispered that it was hidden within the ruins of a long-lost civilization, guarded by deadly traps and treacherous terrain.\n",
      "\n",
      "As I pushed through the underbrush, I stumbled upon a clearing, and my eyes widened in awe. Before me lay the entrance to the ancient city, a sprawling complex of crumbling temples and pyramids. I could feel the excitement coursing through my veins as I approached the entrance.\n",
      "\n",
      "Suddenly, I heard the sound of rustling leaves behind me. I turned to see a rival treasure hunter, the notorious Dr. Vortex, emerging from the jungle. His eyes locked onto mine, and a sinister grin spread across his face.\n",
      "\n",
      "\"You'll never find the Golden Idol before me,\" he sneered, his voice dripping with malice.\n",
      "\n",
      "I knew I had to move fast. I began to sprint through the ruins, dodging ancient stone statues and leaping over treacherous pitfalls. Dr. Vortex was hot on my heels, his footsteps echoing through the city.\n",
      "\n",
      "**Cue: Speed up to 7.2 mph for the next 0.5 miles**\n",
      "\n",
      "As I ran, I could hear the sound of deadly traps springing to life around me. I dodged swinging blades and leapt over pressure plates, my heart racing with excitement and fear.\n",
      "\n",
      "After a few minutes of intense running, I reached the first temple, where I had to solve a puzzle to unlock the door. I quickly worked through the ancient symbols, and the door creaked open, revealing a hidden chamber.\n",
      "\n",
      "Dr. Vortex was closing in, and I knew I had to keep moving. I sprinted through the chamber, my footsteps echoing off the stone walls.\n",
      "\n",
      "**Cue: Slow down to 2.5 mph for a 0.2-mile walk**\n",
      "\n",
      "As I walked, I caught my breath and took a moment to survey my surroundings. The chamber was filled with ancient artifacts and treasures, but I knew I had to keep my focus on the Golden Idol.\n",
      "\n",
      "I continued on, navigating through the winding tunnels and chambers of the ancient city. Dr. Vortex was still hot on my heels, but I knew I had the upper hand.\n",
      "\n",
      "**Cue: Speed up to 7.2 mph for the next 0.5 miles**\n",
      "\n",
      "As I ran, I could hear the sound of the jungle growing louder, and I knew I was getting close to the treasure. I burst through the final door, and my eyes widened in awe. Before me lay the Golden Idol, glinting in the sunlight.\n",
      "\n",
      "Dr. Vortex was right behind me, but I was too quick. I snatched the idol and held it aloft, triumphant.\n",
      "\n",
      "**Cue: Slow down to 2.5 mph for the final 0.5 miles**\n",
      "\n",
      "As I walked back through the ruins, I couldn't help but feel a sense of pride and accomplishment. I had outrun the deadly traps, outsmarted Dr. Vortex, and claimed the Golden Idol.\n",
      "\n",
      "And now, as I emerge from the jungle, I know that I've got the mental and physical toughness to conquer the half-marathon ahead. Bring it on!\n",
      "\n",
      "**Total Distance: 13.1 miles**\n",
      "\n",
      "I hope you enjoy this story! Let me know if you need any changes.\n"
     ]
    }
   ],
   "source": [
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "output = tokenizer.decode(response, skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_response(\"LLAMA3-8B-INSTRUCT\", hyperparams, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "# input_texts = [\"lorem ipsum\", \"Happy Birthday!\", \"Bienvenue\"]\n",
    "# results = perplexity.compute(model_id=model_id,\n",
    "#                              add_start_token=False,\n",
    "#                              predictions=input_texts, \n",
    "#                              device=\"cuda\")\n",
    "# print(list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(round(results[\"mean_perplexity\"], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
