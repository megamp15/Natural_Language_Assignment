{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "from utils import save_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3 - 8B Instruct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c6e081dccb4dd1b28a32f7bf720464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedbbf7b402a4f93a4b542b2df0c4a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359eda61716642708f71130a75976478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf89e4cb9cf457ab3878fec8c9ab13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd09e02fa40c410cab9f38a1a1060371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6016e930cb1646859f10e11051d9028e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b29621fd2543eea7a480851658947e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee92ad809b54866bdc704a118137a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"We have created a fitness app that helps users train for marathons. The app uses stories to help users train. The stories are generated based on user input/biometric data. \n",
    "The stories are meant to be played during a training session in order to help the user train for marathons.\n",
    "You are a AI judge who rates and determines which output better fits the following criteria. The first criteria is the prompt, the second is the distance of the walk/run, \n",
    "the third is the average walking speed, the fourth is the average running speed, and the fifth is the training style (such as endurance run, walk, or anaerobic sprints). \n",
    "The story should have embedded cues for user speed changes and breaks where approriate depending on the Training Style.\n",
    "\n",
    "Your job is to critique all of the different outputs and determine which one is the best. You will be given a prompt and the criteria listed above.\n",
    "Rank all criteria seperately and then average the scores and give an overall score on a scale of 1-100. \"\"\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": f\"\"\"Here is the first output which starts with the prompt and then the story. \\n:\n",
    "     \n",
    "Prompt: A zombie horror story set in New York City.\n",
    "Distance: 0.5 miles\n",
    "Average Walking Speed: 2 mph\n",
    "Average Running Speed: 5 mph\n",
    "Training Style: Short-distance sprint\n",
    "\n",
    "Title : \"Escape from Ground Zero\" (Zombies of NYC) - Marathon Survival Story, \n",
    "\n",
    "Part I [Short Distance Sprint]​[Mile Marker Reached – Start Line / Remainder Miles Left =  1 MILES LEFT ] \n",
    "​In an eerily quiet city once known as bustling metropolis now lies desolate streets filled only silence...and hunger! You find yourself running through Times Square at breakneck speeds; your heart pounded against chest like drums playing out their own macabre symphony . As adrenaline courses though veins ,you can feel every muscle strained under exertion but there’ s no time left stop or rest ! Behind comes hordes undead creatures shambling towards ground zero—the epicenter outbreak which has turned this concrete jungle into nightmare landscape teemming flesh eating monstrosities lurking around each corner waiting pounce unsuspect victims.\n",
    "[RUNNING SPEED CUE HERE][BREAK AFTER HALF MILE REACHED OR WHEN USER NEARLY EXHAUSTION SET IN AND THIRSTY FOR WATERS STOP AT FONTANESCA FOUNTAIN TO TEMPORARY QUench YOUR Thirst BEFORE CONTinuing RACE WITH DEATH.] \n",
    "\n",
    "In front stands towering skyscrapers casting long shadows over desert roads below them while above looms dark clouds threatening rainstorm imminent adding another layer dread hanging heavy air all round us.. But we must press forward if hope survive![END OF BLOCK ONE].As our hero continues his desperate flight across Manhattan he encounters more obstacles than ever before — abandoned cars blocking pathways forcing him jump onto rooftops dodge falling debris narrowly escaping certain doom again &again…But still they keep coming closer faster bit harder claw marks scratch deep gashes skin leaving behind trail bloodied footprints mark territory ahead….Will power surging within fuel final push escape? Or shall fate claim victory here amid ruination remains former empire state building ? Only one way know....Keep moving!!!!!\n",
    "(Racing Heartbeat Sound Effect Here)[Running Resumes After Break End). \n",
    "\n",
    "With renew determination grip tightened fists gritted teeth glaring eyes fixed straight road stretching endlessly uphill battle seems never ending yet somehow strength found reserves hidden depth unbeknown even ourselves until tested such extremity survival instinct kicks gear pushing body beyond\n",
    "\n",
    "\"\"\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "c:\\Users\\pmahi\\OneDrive\\Desktop\\MP\\Drexel\\Courses\\CS614-900 - Applications in Machine Learning\\Projects\\Natural_Language_Assignment\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:649: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"max_new_tokens\": 256, \n",
    "    \"temperature\":0.6, \n",
    "    \"top_p\":0.9, \n",
    "    \"do_sample\": True\n",
    "}\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=hyperparams[\"max_new_tokens\"],\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=hyperparams[\"do_sample\"],\n",
    "    temperature=hyperparams[\"temperature\"],\n",
    "    top_p=hyperparams[\"top_p\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll rate each criterion separately and then average the scores to give an overall score.\n",
      "\n",
      "**Prompt (20 points):**\n",
      "The prompt is creative and engaging, setting the scene for a thrilling zombie horror story. The use of vivid descriptions and imagery helps to immerse the user in the narrative. Score: 18/20\n",
      "\n",
      "**Distance (20 points):**\n",
      "The distance of 0.5 miles is accurately reflected in the story, with a clear separation between the initial sprint and the subsequent break. Score: 19/20\n",
      "\n",
      "**Average Walking Speed (20 points):**\n",
      "The story does not explicitly mention walking speed, but the initial sprint is described as \"breakneck speeds\" which is consistent with a higher running speed. However, the story does not account for the average walking speed of 2 mph. Score: 12/20\n",
      "\n",
      "**Average Running Speed (20 points):**\n",
      "The initial sprint is described as \"breakneck speeds\" which is consistent with a higher running speed, and the subsequent break allows the user to recover before resuming at a higher intensity. Score: 18/20\n",
      "\n",
      "**Training Style (20 points):**\n",
      "The story accurately reflects the short-distance sprint training style, with a clear emphasis on speed and intensity. The inclusion of a break\n"
     ]
    }
   ],
   "source": [
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "output = tokenizer.decode(response, skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_response(\"LLAMA3_JUDGE\", hyperparams, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "# input_texts = [\"lorem ipsum\", \"Happy Birthday!\", \"Bienvenue\"]\n",
    "# results = perplexity.compute(model_id=model_id,\n",
    "#                              add_start_token=False,\n",
    "#                              predictions=input_texts, \n",
    "#                              device=\"cuda\")\n",
    "# print(list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(round(results[\"mean_perplexity\"], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
