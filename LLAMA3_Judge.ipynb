{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "from utils import save_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3 - 8B Instruct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dadfeb980294715b2307fe36b3dbdb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427f2b8e192a439c827f8a184b89822f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c5c3aae3ac4ff186a4fcad5b77a8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df69ad16e6c44de4a9e1934d0ecae638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886a27b8d194478a910dc9eae1a45f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f485b0df21b4334844f0d7ad5a60f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be4551c6771422d97b3e54295300619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331dbd834167437c8a8ae1d2e175dfe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c1a4ec37944fe98834643e57d5ca95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4151c8f1c64cab8a806984704b2ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d67e0380ba641a9986a83706baa9eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ff728cc9ca40b6971c3bc1321bc6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"We have created a fitness app that helps users train for marathons. The app uses stories to help users train. The stories are generated based on user input/biometric data. \n",
    "The stories are meant to be played during a training session in order to help the user train for marathons.\n",
    "You are a AI judge who rates and determines which output better fits the following criteria. The first criteria is the prompt, the second is the distance of the walk/run, \n",
    "the third is the average walking speed, the fourth is the average running speed, and the fifth is the training style (such as endurance run, walk, or anaerobic sprints). \n",
    "The story should have embedded cues for user speed changes and breaks where approriate depending on the Training Style.\n",
    "\n",
    "Your job is to critique all of the different outputs and determine which one is the best. You will be given a prompt and the criteria listed above.\n",
    "Rank all criteria seperately and then average the scores and give an overall score on a scale of 1-100. \"\"\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": f\"\"\"Here is the first output which starts with the prompt and then the story. \\n:\n",
    "     \n",
    "Prompt: A action packed adventure story based off of Indiana Jones, include outrunning deadly traps, a chase scene with a treasure hunter and a villain, jungles and ancient ruins.\n",
    "Distance: 13.1 miles\n",
    "Average Walking Speed: 2.5 mph\n",
    "Average Running Speed: 7.2 mph\n",
    "Training Style: Half Marathon\n",
    "\n",
    "Itâ€™S JULIET! It starts like everyone knows it SHOOTING OFF IN THE GREAT DEADLY TRAPS OF IRON-CLUB WORLD!!!!! He takes his bow but when one appears he droppt down behind some crates ! Then all these things appear around him there s rocks fallng from walls so fast bah BANG !! BOOM THEN HE SWOOPES UP FROM BELOW U SEE PANNED NOW AND IT IS DARKER FINALLY SOUTH FORWARD RIGHT TO GET MOVIE ONSET... (PLAY CATCHUP)....THEN RUNRUN THIS ALL MAKEFULL COMMENT REGIONAL START MUSIC????? HIGHPLEXEL? TRAP ROCK CRASH CLIPPITZCRIIIIIMPLOPE ....GO ALRIGHT .. ANNO YOU OUTLAST EVERDED LANDMANS LIKE RAIDMAN NOODLERS ? Noodler ?? OK , its gonna go nw then run fwd again . ok now we got shots at different angles ... okay here they enter this old village just after warming up maybe get lost or something cause right away people attack them both not slowy as u can see lol I smell gold though why dont thoooosers pick us :p Ok guys running ahead let em pass quickly wtf do i look dumb rn lets continue yay short distance half mile about seven minutes walking time five seconds crossbow shot..walk faster etc walk more slowly turn left going into battle area next stop cutdown wait what oh man first blood very exciting donotlooki know if ill kill anyone im too cool idk how many noobs killed before hauntingman dies looking stupid oops also lots other guns used well anyhow keep shooting die already shoota lot nahh never mind another minute later almost ran someone say \"came\" alright need less background noise take three steps back move forward kick near hand guards slit neak hands knives use gun throw sword slash stab jump climb grab hold claws punches body hit grenades blow torch blaster laser eyes eye cover roar loud boom scream sound stuff coming closer make our heart rate rise because close fighting happens mostly really intense please listen carefully especially big spikes getting smaller while still being huge awesome tails whack head chopping arms swing throwing weapons rolling objects flying overcoming obstacles vicious actions words shoutings speech sounds monkeys speaking animals saying important lines exclamations such statements describing fight scenes including descriptions visualizing surroundling elements characters posotion expression gestures movement scenic designs landscape locations landmarks features environmental settings audio video animation graphical images creatures spirits zombies skeletor evil minters menace darkness flames fire wind smoke rain snow night day sun light shadow lights stars constellaints air clouds mist sandstone rock crystal sky water sprinklers iris earth moon twilight mountains trees branches leaves thick roots flowers flower petals grass shooting star fog silhouette reddish purple blue orange green yellow magenta plasma silver black electric white turquise translucent violets scarlato gray cyan grey teal lavender burgundywine colorful pastel colors aquamarines dark saffron indigo rose tan brown egluksred metallics diamond shapes multicolored spears bulky textured skinny muscular bodies fat thin curvy limbs sharp teeth cladding hair mouthpieces horn antagonist appearance contrast perspective viewpoint narration directors commentary score suspense excitement humor thrilling plot development dramatic music playlist character dialogue setting ambient ambience environment weather atmosphere emotions psychology mental focus inner thoughts feelings dream sequences ideas imagination concept imaginary concepts surreal realistic events fictional scenarios random occurrences memories flashback remembran below showcase replay pause zoom follow directions key tips shortcut footage montages sublimity archery graveyard tomb mausoleum skull face sweat arena steeples cave passageways forest woodlands fields vegetable garden house car park kitchen cupboard roof railing sidewall gatefront yard building ground street corner city roads mountain valley range plaza parkinglot square field court benchtables table chair desklife treehouse room floor hall closet ceileroom basement tunnel ventilation fan engine coils machine assembly section pipelines switchbox mainframe device system interface panel display screen monitor electronic circuit board terminal electron flow current voltage pulsing photon power quantum dynamics atomic scale structures space dimensions frequency cycles periodic patterns energy motion physical laws natural phenomena mathematical theories logic reasoning causality consequence effect theory principle operation component structure mechanism function activity process reaction pattern procedure element sequence step cycle repetition\n",
    "\"\"\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "c:\\Users\\pmahi\\OneDrive\\Desktop\\MP\\Drexel\\Courses\\CS614-900 - Applications in Machine Learning\\Projects\\Natural_Language_Assignment\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:649: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"max_new_tokens\": 256, \n",
    "    \"temperature\":0.6, \n",
    "    \"top_p\":0.9, \n",
    "    \"do_sample\": True\n",
    "}\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=hyperparams[\"max_new_tokens\"],\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=hyperparams[\"do_sample\"],\n",
    "    temperature=hyperparams[\"temperature\"],\n",
    "    top_p=hyperparams[\"top_p\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will critique the output based on the given criteria.\n",
      "\n",
      "**Prompt:** The story starts with the prompt, but it quickly diverges from the adventure story based on Indiana Jones, and instead becomes a chaotic mix of action scenes, trap escapes, and fight sequences. The story fails to incorporate the treasure hunter and the villain, and the jungle and ancient ruins settings are not fully utilized. Score: 20/50\n",
      "\n",
      "**Distance:** The story is approximately 13.1 miles long, which matches the given distance. Score: 50/50\n",
      "\n",
      "**Average Walking Speed:** The story includes walking scenes, but it does not provide clear cues for walking speed changes. The average walking speed is not consistently maintained, and the story jumps between walking and running without clear transitions. Score: 30/50\n",
      "\n",
      "**Average Running Speed:** The story includes running scenes, and the average running speed is occasionally mentioned (e.g., \"RUNRUN THIS ALL MAKEFULL COMMENT REGIONAL START MUSIC?????\"). However, the running speed is not consistently maintained, and the story jumps between walking and running without clear transitions. Score: 40/50\n",
      "\n",
      "**Training Style:** The story includes elements of endurance running, but it also includes anaerobic sprints and walking scenes. The training style\n"
     ]
    }
   ],
   "source": [
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "output = tokenizer.decode(response, skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_response(\"LLAMA3_JUDGE\", hyperparams, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "# input_texts = [\"lorem ipsum\", \"Happy Birthday!\", \"Bienvenue\"]\n",
    "# results = perplexity.compute(model_id=model_id,\n",
    "#                              add_start_token=False,\n",
    "#                              predictions=input_texts, \n",
    "#                              device=\"cuda\")\n",
    "# print(list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(round(results[\"mean_perplexity\"], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
